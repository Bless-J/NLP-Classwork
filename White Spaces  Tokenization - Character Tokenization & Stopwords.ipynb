{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **WHITESPACE TOKENIZATION**"
      ],
      "metadata": {
        "id": "7hJzBYTIe58m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This method counts the white spaces in sentences."
      ],
      "metadata": {
        "id": "bbqduVvTfq8s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GdWWFlHxYwsE"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import WhitespaceTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(text):\n",
        "    tokenizer = WhitespaceTokenizer()\n",
        "    return tokenizer.tokenize(text)"
      ],
      "metadata": {
        "id": "X1XijG40ZDBd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Text = 'Coucou, Ca va?'\n",
        "tokens = tokenize(Text)\n",
        "space_count = Text.count(\" \")\n",
        "print(tokens)\n",
        "print(\"Number of white spaces:\", space_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4j8T8W5iZIeZ",
        "outputId": "a114e8a8-4250-4f73-ea3c-337e2ce9b493"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Coucou,', 'Ca', 'va?']\n",
            "Number of white spaces: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CHARACTER TOKENIZATION**"
      ],
      "metadata": {
        "id": "d_2F7jhnepVB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Character tokenization breaks a text into individual characters, instead of words or subwords."
      ],
      "metadata": {
        "id": "J-0m1RMFf2Yw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n"
      ],
      "metadata": {
        "id": "K_nN56k2bdjc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def char_level_tokenizer(text):\n",
        "    return list(text)\n",
        "\n",
        "tokens = char_level_tokenizer(\"How are you doing?\")\n",
        "print(tokens)"
      ],
      "metadata": {
        "id": "gQ4hBHeWcmv1",
        "outputId": "540ada8f-bf3e-4395-fcd2-ce85aa27623f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['H', 'o', 'w', ' ', 'a', 'r', 'e', ' ', 'y', 'o', 'u', ' ', 'd', 'o', 'i', 'n', 'g', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **STOPWORDS**"
      ],
      "metadata": {
        "id": "CsbDw0JtXSvU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stopwords are the common, frequently used words in a language that usually donâ€™t add much meaning to a sentence."
      ],
      "metadata": {
        "id": "3HPtBprIcEbd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Download stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "#list of words\n",
        "words = [\"I\", \"believe\", \"that\", \"all\", \"will\", \"be\", \"well\"]\n",
        "\n",
        "# Remove stop words\n",
        "filtered = [word for word in words if word.lower() not in stopwords.words(\"english\")]\n",
        "\n",
        "print(filtered)"
      ],
      "metadata": {
        "id": "g8xASx5ht62I",
        "outputId": "cfa6a0ae-39d2-4c2e-ebbb-793100bf381f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['believe', 'well']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    }
  ]
}